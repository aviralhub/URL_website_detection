{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPEuaqkn+HE99adRlfXdsVL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aviralhub/URL_website_detection/blob/main/MnistProject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "IMPORT THE LIBRARIES"
      ],
      "metadata": {
        "id": "gO8GKUUjYSl7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import Sequential\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization, Dropout, Flatten, Dense\n",
        "from tensorflow.keras.initializers import HeNormal\n",
        "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, BatchNormalization, Dropout\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "zJHtn5tzWSFq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "# Normalize the pixel values to a range of [0, 1]\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# Reshape the data to include a single color channel (grayscale)\n",
        "x_train = x_train.reshape(-1, 28, 28, 1)\n",
        "x_test = x_test.reshape(-1, 28, 28, 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IXfX8vnSWTGl",
        "outputId": "a932ce87-d27c-4a6e-c600-7c7664243600"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZrxTfrBTYzTe",
        "outputId": "9ce3301a-e741-4069-c793-5d8da27a8e12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28, 1)\n",
            "(60000,)\n",
            "(10000, 28, 28, 1)\n",
            "(10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "VISUALIZE THE DATA"
      ],
      "metadata": {
        "id": "N5pTuDCEYZmI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Display the first image in the training set\n",
        "plt.imshow(x_train[3].reshape(28, 28), cmap='gray')  # Reshape to 28x28 and show in grayscale\n",
        "plt.title(f\"Label: {y_train[3]}\")  # Display the label of the image\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "bhZQmnMfWZsI",
        "outputId": "163fa6c3-a262-4a2b-9c1f-14689c8a432c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MODEL"
      ],
      "metadata": {
        "id": "jsEIgr0WYh5n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "he_normal = HeNormal()\n",
        "\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', kernel_initializer=he_normal, input_shape=(28, 28, 1)),\n",
        "    Conv2D(64, (3, 3), activation='relu', kernel_initializer=he_normal),\n",
        "    MaxPooling2D((2, 2)),\n",
        "\n",
        "    Conv2D(64, (3, 3), activation='relu', kernel_initializer=he_normal),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.1),\n",
        "\n",
        "    Conv2D(128, (3, 3), activation='relu', kernel_initializer=he_normal),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D((2, 2)),\n",
        "\n",
        "    Conv2D(256, (3, 3), activation='relu', kernel_initializer=he_normal),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.1),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu', kernel_initializer=he_normal),\n",
        "    Dense(64, activation='relu', kernel_initializer=he_normal),\n",
        "    Dense(10, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GxLsDbauWa-u",
        "outputId": "93369b04-0512-4552-b5ec-461cb20726f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        },
        "id": "npz-pwyMWgiE",
        "outputId": "ae3d0805-d478-4b39-c19d-6b1fb342fc40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m320\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m36,928\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │        \u001b[38;5;34m73,856\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │           \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │       \u001b[38;5;34m295,168\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │         \u001b[38;5;34m1,024\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m131,200\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m650\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,200</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m566,666\u001b[0m (2.16 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">566,666</span> (2.16 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m565,770\u001b[0m (2.16 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">565,770</span> (2.16 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m896\u001b[0m (3.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> (3.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import Sequential\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization, Dropout, Flatten, Dense\n",
        "from tensorflow.keras.initializers import HeNormal\n",
        "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, BatchNormalization, Dropout\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import numpy as np\n",
        "\n",
        "# Load MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0  # Normalize\n",
        "x_train = x_train.reshape(-1, 28, 28, 1)\n",
        "x_test = x_test.reshape(-1, 28, 28, 1)\n",
        "\n",
        "num_folds = 7\n",
        "skf = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
        "k_fold_accuracies = []\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(skf.split(x_train, y_train)):\n",
        "    print(f\"\\nTraining Fold {fold+1}/{num_folds}...\")\n",
        "\n",
        "    x_train_fold, x_val_fold = x_train[train_idx], x_train[val_idx]\n",
        "    y_train_fold, y_val_fold = y_train[train_idx], y_train[val_idx]\n",
        "\n",
        "    he_normal = HeNormal()\n",
        "\n",
        "    model = Sequential([\n",
        "        Conv2D(32, (3, 3), activation='relu', kernel_initializer=he_normal, input_shape=(28, 28, 1)),\n",
        "        Conv2D(64, (3, 3), activation='relu', kernel_initializer=he_normal),\n",
        "        MaxPooling2D((2, 2)),\n",
        "\n",
        "        Conv2D(64, (3, 3), activation='relu', kernel_initializer=he_normal),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.1),\n",
        "\n",
        "        Conv2D(128, (3, 3), activation='relu', kernel_initializer=he_normal),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling2D((2, 2)),\n",
        "\n",
        "        Conv2D(256, (3, 3), activation='relu', kernel_initializer=he_normal),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.1),\n",
        "\n",
        "        Flatten(),\n",
        "        Dense(128, activation='relu', kernel_initializer=he_normal),\n",
        "        Dense(64, activation='relu', kernel_initializer=he_normal),\n",
        "        Dense(10, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "    early_stopping = tf.keras.callbacks.EarlyStopping(patience=3, min_delta=0.01, restore_best_weights=True)\n",
        "\n",
        "    history = model.fit(x_train_fold, y_train_fold, epochs=10, batch_size=32,\n",
        "                        validation_data=(x_val_fold, y_val_fold), callbacks=[early_stopping])\n",
        "\n",
        "    val_loss, val_acc = model.evaluate(x_val_fold, y_val_fold)\n",
        "    k_fold_accuracies.append(val_acc)\n",
        "    print(f\"Fold {fold+1} Accuracy: {val_acc:.4f}\")\n",
        "\n",
        "print(f\"\\nFinal K-Fold Accuracy: {np.mean(k_fold_accuracies):.4f} ± {np.std(k_fold_accuracies):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dum0cJDlWmR7",
        "outputId": "0995191a-d11d-49e4-c550-cadf65b26621"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training Fold 1/7...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.9290 - loss: 0.2315 - val_accuracy: 0.9830 - val_loss: 0.0607\n",
            "Epoch 2/10\n",
            "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9844 - loss: 0.0540 - val_accuracy: 0.9798 - val_loss: 0.0789\n",
            "Epoch 3/10\n",
            "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9864 - loss: 0.0456 - val_accuracy: 0.9847 - val_loss: 0.0545\n",
            "Epoch 4/10\n",
            "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9887 - loss: 0.0358 - val_accuracy: 0.9857 - val_loss: 0.0561\n",
            "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9820 - loss: 0.0584\n",
            "Fold 1 Accuracy: 0.9830\n",
            "\n",
            "Training Fold 2/7...\n",
            "Epoch 1/10\n",
            "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.9276 - loss: 0.2295 - val_accuracy: 0.9812 - val_loss: 0.0653\n",
            "Epoch 2/10\n",
            "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.9835 - loss: 0.0568 - val_accuracy: 0.9704 - val_loss: 0.0996\n",
            "Epoch 3/10\n",
            "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9884 - loss: 0.0390 - val_accuracy: 0.9882 - val_loss: 0.0475\n",
            "Epoch 4/10\n",
            "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.9895 - loss: 0.0346 - val_accuracy: 0.9881 - val_loss: 0.0546\n",
            "Epoch 5/10\n",
            "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9912 - loss: 0.0283 - val_accuracy: 0.9872 - val_loss: 0.0565\n",
            "Epoch 6/10\n",
            "\u001b[1m1608/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9923 - loss: 0.0242 - val_accuracy: 0.9900 - val_loss: 0.0395\n",
            "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9871 - loss: 0.0504\n",
            "Fold 2 Accuracy: 0.9882\n",
            "\n",
            "Training Fold 3/7...\n",
            "Epoch 1/10\n",
            "\u001b[1m1548/1608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9265 - loss: 0.2340"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create subplots\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(13.5, 5))\n",
        "\n",
        "# Plot training & validation loss\n",
        "loss_train = history.history['loss']\n",
        "loss_val = history.history['val_loss']\n",
        "epochs = range(1, len(loss_train) + 1)\n",
        "ax1.plot(epochs, loss_train, label='Training Loss')\n",
        "ax1.plot(epochs, loss_val, label='Validation Loss')\n",
        "ax1.set_title('Training and Validation Loss')\n",
        "ax1.set_xlabel('Epochs')\n",
        "ax1.set_ylabel('Loss')\n",
        "ax1.legend()\n",
        "\n",
        "# Plot training & validation accuracy (categorical accuracy for MNIST)\n",
        "acc_train = history.history['accuracy']  # Use 'accuracy' instead of 'binary_accuracy'\n",
        "acc_val = history.history['val_accuracy']\n",
        "epochs = range(1, len(acc_train) + 1)\n",
        "ax2.plot(epochs, acc_train, label='Training Accuracy')\n",
        "ax2.plot(epochs, acc_val, label='Validation Accuracy')\n",
        "ax2.set_title('Training and Validation Accuracy')\n",
        "ax2.set_xlabel('Epochs')\n",
        "ax2.set_ylabel('Accuracy')\n",
        "ax2.legend()\n",
        "\n",
        "# Print best validation loss and accuracy\n",
        "print(\"Best Validation Loss: \", min(history.history['val_loss']))\n",
        "print(\"Best Validation Accuracy: \", max(history.history['val_accuracy']))\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kGj7b1BFX5JU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, classification_report, precision_score, recall_score, f1_score\n",
        "\n",
        "# Get model predictions\n",
        "y_pred = model.predict(x_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)  # Convert probabilities to class labels\n",
        "\n",
        "# Compute confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred_classes)\n",
        "\n",
        "# Compute precision, recall (sensitivity), and F1 score for each class\n",
        "report = classification_report(y_test, y_pred_classes, output_dict=True)\n",
        "\n",
        "# Extract overall precision, recall (macro/micro averages), and F1 score\n",
        "overall_precision = precision_score(y_test, y_pred_classes, average='macro')  # Macro: unweighted mean\n",
        "overall_recall = recall_score(y_test, y_pred_classes, average='macro')  # Macro recall\n",
        "overall_f1 = f1_score(y_test, y_pred_classes, average='macro')  # Macro F1 score\n",
        "\n",
        "# Compute TP, FP, FN, TN, specificity, and FPR for each class\n",
        "num_classes = cm.shape[0]\n",
        "tp_fp_fn_tn = {}\n",
        "\n",
        "TP,FP,FN,TN = 0,0,0,0\n",
        "\n",
        "specificities = []\n",
        "fprs = []\n",
        "for class_label in range(num_classes):\n",
        "    tp = cm[class_label, class_label]  # True Positives\n",
        "    fp = np.sum(cm[:, class_label]) - tp  # False Positives\n",
        "    fn = np.sum(cm[class_label, :]) - tp  # False Negatives\n",
        "    tn = np.sum(cm) - (tp + fp + fn)  # True Negatives\n",
        "\n",
        "    specificity = tn / (tn + fp) if (tn + fp) != 0 else 0  # Specificity\n",
        "    fpr = fp / (fp + tn) if (fp + tn) != 0 else 0  # False Positive Rate\n",
        "    specificities.append(specificity)\n",
        "    fprs.append(fpr)\n",
        "\n",
        "    TP+=tp\n",
        "    FP+=fp\n",
        "    FN+=fn\n",
        "    TN+=tn\n",
        "\n",
        "    tp_fp_fn_tn[class_label] = {\n",
        "        \"TP\": tp, \"FP\": fp, \"FN\": fn, \"TN\": tn, \"Specificity\": specificity, \"FPR\": fpr\n",
        "    }\n",
        "\n",
        "# Overall specificity and FPR\n",
        "overall_specificity = np.mean(specificities)\n",
        "overall_fpr = np.mean(fprs)\n",
        "\n",
        "# Overall accuracy\n",
        "accuracy = np.sum(np.diag(cm)) / np.sum(cm)\n",
        "\n",
        "# Print overall metrics\n",
        "print(f\"Overall Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Overall Precision: {overall_precision:.4f}\")\n",
        "print(f\"Overall Recall (Sensitivity): {overall_recall:.4f}\")\n",
        "print(f\"Overall F1 Score: {overall_f1:.4f}\")\n",
        "print(f\"Overall Specificity: {overall_specificity:.4f}\")\n",
        "print(f\"Overall FPR: {overall_fpr:.4f}\")\n",
        "\n",
        "\n",
        "# Print the full confusion matrix\n",
        "\n",
        "print(f\"TP: {TP}\")\n",
        "print(f\"FP: {FP}\")\n",
        "print(f\"FN: {FN}\")\n",
        "print(f\"TN: {TN}\")"
      ],
      "metadata": {
        "id": "k74HL_uPWuZZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import save_model\n",
        "model.save('Mnist_10_model')"
      ],
      "metadata": {
        "id": "gT8weFSYbc0M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FhcvpRJibmAi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}